---
title: "Differential Gene Expression"
subtitle: "RAdelaide 2024"
author: "Dr Stevie Pederson"
institute: |
  | Black Ochre Data Labs
  | Telethon Kids Institute
date: "2024-07-11"
date-format: long
bibliography: bibliography.bib
title-slide-attributes:
    data-background-color: "#3d3d40"
    data-background-image: assets/bodl_logo_white_background.jpg
    data-background-opacity: "0.3"
    data-background-size: "90%"
editor: source
format:
  revealjs:
    theme: [bodl.scss]
    code-line-numbers: false
    width: 1280
    height: 720
    sansfont: Times New Roman
    logo: assets/bodl_logo_white_background.jpg
    slide-number: c
    show-slide-number: all
  html:
    css: [bodl.scss, extra.css]
    output-file: deg.html
    embed-resources: true
    toc: true
    toc-depth: 1
include-after: |
  <script type="text/javascript">
    Reveal.on('ready', event => {
      if (event.indexh === 0) {
        document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
      }
    });
    Reveal.addEventListener('slidechanged', (event) => {
      if (event.indexh === 0) {
        Reveal.configure({ slideNumber: null });
        document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
      }
      if (event.indexh === 1) {
        Reveal.configure({ slideNumber: 'c' });
        document.querySelector("div.has-logo > img.slide-logo").style.display = null;
      }
    });
  </script>
knitr:
  opts_chunk:
    echo: true
    include: true
    warning: false
    message: false
    fig.align: center
    fig.height: 6
    fig.width: 8
---

# Differential Gene<br>Expression {background-color="#3c3c44" background-image=https://raw.githubusercontent.com/Bioconductor/BiocStickers/devel/edgeR/edgeR.png background-size="30%" background-opacity="0.4" background-position='80% 50%'}

```{r, echo=FALSE}
options(width = 100)
```

## Differential Gene Expression

- The most common question: <br>*Which genes change expression levels in response to a treatment?*

. . .

- Need to perform a statistical test on each gene
    + Select genes-of-interest using some criteria

. . .

- Dealing with count data $\implies$ can't be Normally distributed
- Generally assumed to have a Negative Binomial distribution
    + Essentially a Poisson distribution with additional variability   

## Today's Data

- Data obtained from Gene Expression Omnibus [GSE171742](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE171742)
- Stem cell derived cardiomyocytes with 4 treatment groups [@Liu2023-qu]
- All transfected using lentiviral vectors

. . .

1. Control
2. Nsp6 over-expression
3. Nsp8 over-expression
4. M over-expression


## Today's Data

![](assets/Liu_paper.png){fig-align="left"}

## Today's Data

- Well documented [metadata](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM5233239)! &#129299;
- We know exact versions of all tools and annotations

![](assets/GEO_description.png){.absolute left=0 bottom=100 width=1000}

## Loading Packages


```{r packages}
library(tidyverse)
library(magrittr)
library(edgeR)
library(AnnotationHub)
library(rtracklayer)
library(plyranges)
library(patchwork)
library(scales)
library(glue)
library(ggrepel)
library(pheatmap)
library(parallel)
theme_set(theme_bw())
```

## Getting Annotations

- Which one shall we choose?

::: {style="font-size: 90%;"}

```{r ah, cache=TRUE}
ah <- AnnotationHub()
ah %>% subset(dataprovider == "Gencode" & genome == "GRCh38") %>% query("v31")
```

:::

## Getting Annotations

::: {style="font-size: 95%;"}

```{r genes, cache=TRUE}
gtf <- ah[["AH75121"]] # This will take several minutes
genes <- gtf %>% 
  filter(type == "gene") %>% 
  select(starts_with("gene"))
genes
```

:::

## Getting Gene Lengths

- The simplest way is to add the width of all exonic regions

```{r}
gene_lengths <- gtf %>% 
  filter(type == "exon") %>% 
  split(.$gene_id) %>% 
  reduce() %>% 
  width() %>% 
  mclapply(sum, mc.cores = 4) %>% 
  unlist()
genes$length <- gene_lengths[genes$gene_id]
```


## Loading Counts

- Data is exactly as produced by `featureCounts` [@Liao2014-gy]
    + Tab-delimited but with some weird columns
- Let's have a sneak preview

. . .

```{r}
read_tsv("data/GSE171742_counts.out.gz", n_max = 6)
```

. . .

Which columns do we need? How would you parse them?

## Loading Counts

- The best form for counts is as a matrix

```{r}
counts <- read_tsv("data/GSE171742_counts.out.gz") %>% 
  dplyr::select(Geneid, contains("_")) %>% 
  as.data.frame() %>% 
  column_to_rownames("Geneid") %>% 
  as.matrix()
glimpse(counts)
```

## Checking Annotations

- Compare these with the annotations we have

```{r}
setdiff(rownames(counts), genes$gene_id)
```

::: {.notes}
- If we're doing everything, we don't need to check these
- Only for public data. Annotations can be difficult to untangle
:::

- Should we remove the suffixes?

## Checking Annotations

```{r}
genes %>% subset(gene_id == "ENSG00000002586.20")
```

- How can we resolve this?

## Checking Annotations

```{r}
genes <- genes %>% 
  mutate(
    gene_id = case_when(
      duplicated(gene_id) ~ paste0(gene_id, "_PAR_Y"),
      TRUE ~ gene_id
    )
  ) 
subset(genes, duplicated(gene_id))
```


# DGE Analysis {background-color="#3c3c44" background-image=https://raw.githubusercontent.com/Bioconductor/BiocStickers/devel/edgeR/edgeR.png background-size="30%" background-opacity="0.4" background-position='80% 50%'}

## Basic Workflow

1. Remove low-expressed & undetectable genes
2. Normalise the data
3. Estimate dispersions
4. Perform Statistical Tests
5. Enrichment Testing

. . .

- Careful checks at every step to inform decisions

## DGEList Objects

- We'll use `edgeR` for DGE analysis [@edgeR2010]
- Counts, sample metadata and gene annotations stored in a single `S4` object
    + `DGEList`: *Digital* Gene Expression List
    + Gene & metadata elements need to be `data.frame` objects
    + Will be coerced if able
. . .

- `DESeq2` is a common alternative [@DESeq22014]
- Uses an extension of `SummarizedExperiment` objects

::: {.notes}
- Both methods are gold-standard but neither perfect for every dataset
- Both Wolfgang Huber & Gordon Smyth are exceptional statisticians
- Will try get to DESeq2 later in the session
:::

## DGEList Objects

- How can we get sample metadata?

```{r}
samples <- tibble(id = colnames(counts)) %>% 
  separate(id, into = c("replicate", "treatment"), remove = FALSE) %>% 
  mutate(
    treatment = as.factor(treatment),
    group = as.integer(treatment)
  )
samples
```

::: {.notes}
Will be in the same order as `counts`
:::

## DGEList Objects

- Annotations appear to match the counts
    + Counts for `r comma(nrow(counts))` genes
    + Annotations for `r comma(length(genes))` genes
- But will be in a different order
    + Counts in order of name
    + Annotations in genomic order

## DGEList Objects
    
```{r}
genes %>% setNames(.$gene_id) %>% .[rownames(counts)]
```

## DGEList Objects

```{r}
dge <- DGEList(
  counts = counts,
  samples = tibble(id = colnames(counts)) %>% left_join(samples),
  genes = genes %>% 
    setNames(.$gene_id) %>% 
    .[rownames(counts)] %>% 
    as.data.frame(row.names = names(.))
)
dge
```

## DGEList Objects

- Key elements have different but related dimensions

```{r}
dim(dge)
dim(dge$counts)
dim(dge$samples)
dim(dge$genes)
```

- `samples` is column metadata $\implies$ `genes` is row metadata

## Library Sizes

- The very first step with counts $\implies$ library sizes
- This is the total number of reads (i.e. RNA fragments) assigned to genes
- Ideally >20m reads per sample
- Those below 10m reads are generally considered as problematic
    + Context dependent

## Library Sizes

```{r plot-lib-size}
#| fig-height: 5
#| fig-show: hide
dge$samples %>% 
  ggplot(aes(replicate, lib.size / 1e6, fill = treatment)) +
  geom_col() +
  facet_wrap(~treatment, nrow = 1, scales = "free_x") +
  labs(x = "Sample", y = "Library Size (millions)", fill = "Treatment") +
  scale_y_continuous(expand = expansion(c(0, 0.05))) +
  scale_fill_brewer(palette = "Set1")
```

::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/plot-lib-size-1.png)

:::

## Library Sizes

- We can get fancy and add the mean value 

```{r lib-size-with-mean}
#| fig-show: hide
#| fig-height: 5
dge$samples %>% 
  ggplot(aes(replicate, lib.size / 1e6, fill = treatment)) +
  geom_col() +
  geom_hline(
    aes(yintercept = lib.size),
    data = . %>% summarise(lib.size = mean(lib.size / 1e6)),
    linetype = 2, colour = "grey30"
  ) +
  facet_wrap(~treatment, nrow = 1, scales = "free_x") +
  labs(x = "Sample", y = "Library Size (millions)", fill = "Treatment") +
  scale_y_continuous(expand = expansion(c(0, 0.05))) +
  scale_fill_brewer(palette = "Set1")
```

::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/lib-size-with-mean-1.png)

:::

::: {.notes}
These look like really good libraries so far
:::

## Detected Vs Undetected Genes

- By adding counts across samples and seeing how many are zero<br>$\implies$ non-detectable genes

```{r}
dge$counts %>% 
  rowSums() %>% 
  equals(0) %>% 
  sum()
```

. . .

- Genes with low counts can also be removed
    + These end up being highly variable
    + Uninformative statistically

## Detected Vs Undetected Genes

- No set method for considering a gene as *too low to bother with*
- Can use raw counts below some value
- Counts within a group above some value $\implies$ detected within a treatment

. . .

- Counts per million reads (CPM) is a common measure used in abundance analysis 
- Take the library sizes / 1e6 & divide counts by this value $\implies$ CPM
- Can also use logCPM
    + Adds a non-zero value to every gene to avoid zeroes

## Detected Vs Undetected Genes

- `edgeR` provides a function `filterByExpr()`
- Flags genes for removal or discarding based on counts
- Set minimum CPM as `min.count` $\times 1e6$ / `median(lib.size)`
- Set minimum *total counts*

. . .

- Genes are retained if CPM > minCPM in $\geq n$ samples
    + $n$ is the smallest treatment group


- Default settings may be a little generous for this dataset

## Detected Vs Undetected Genes
    
- If we require > 1CPM in at least 3 samples

```{r}
min_count <- dge$samples$lib.size %>% 
  median() %>% 
  divide_by(1e6) %>% 
  round(0)
min_count
min_total <- 150
keep <- filterByExpr(dge, min.count = min_count, min.total.count = 150)
```


## Detected Vs Undetected Genes

::: {style="font-size: 95%;"}

```{r plot-densities}
#| fig-show: hide
#| fig-height: 5
A <- dge$counts %>% 
  cpm(log = TRUE) %>% 
  as_tibble(rownames = "gene_id") %>% 
  pivot_longer(-all_of("gene_id"), names_to = "id", values_to = "logCPM") %>% 
  left_join(dge$samples) %>% 
  ggplot(aes(logCPM, after_stat(density), group = id)) +
  geom_density(aes(colour = treatment)) +
  ggtitle(glue("Before Filtering: {comma(length(keep))} genes")) +
  labs(y = "Density", colour = "Treatment") +
  scale_colour_brewer(palette = "Set1")
B <- dge$counts[keep,] %>% 
  cpm(log = TRUE) %>% 
  as_tibble(rownames = "gene_id") %>% 
  pivot_longer(-all_of("gene_id"), names_to = "id", values_to = "logCPM") %>% 
  left_join(dge$samples) %>% 
  ggplot(aes(logCPM, after_stat(density), group = id)) +
  geom_density(aes(colour = treatment)) +
  ggtitle(glue("After Filtering: {comma(sum(keep))} genes")) +
  labs(y = "Density", colour = "Treatment") +
  scale_colour_brewer(palette = "Set1")
A + B + plot_layout(guides = "collect", axes = "collect")
```

:::

::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/plot-densities-1.png)

:::

## Detected Vs Undetected Genes

- Create new object once satisfied with the filtering strategy
- Passing the logical vector will subset `counts` & `genes` correctly
    + The original library sizes are retained

```{r}
dge_filter <- dge[keep,]
dge_filter
```



## Normalisation

- Normalisation is a very common step in transcriptomic analysis
- Helps to account for differences in library composition
    + e.g. are some libraries dominated by a handful of highly abundant genes
- The default in `edgeR` is TMM [@Robinson2010-qp]
- `DESeq2` uses RLE normalisation
    + Very similar in principle
    
## Statistical Analysis of Counts

- Poisson models number of events per unit
    + e.g. telephone calls per minute
- The rate parameter ($\lambda$) models this
- mean occurrence = average rate = $\lambda$
- Variance is fixed at $\lambda$
    + If variance $\neq \lambda \implies$ not Poisson data 
    
. . .

- The basic model for `edgeR` is a Negative Binomial Model
    + NB: mean = $\lambda$; variance = $\lambda + r$
- Multiple strategies for obtaining estimates
    
## Statistical Analysis of Counts

- Counts / gene (i.e. $y_{gi}$) are a function of library size ($L_i$)
- Gene length is fixed across samples $\implies$ library size is not
- Dividing by library size is a way of normalising counts

$$
\log (y_{gi} / L_i) = \beta_0 + \beta_1 + ...
$$

## Normalisation

- Calculation of normalisation factors ($Y_i$) per sample
    + The idealised normalisation factor is $Y_i = 1$
- Can use scaled library sizes $L^*_i = Y_i \times L_i$

$$
\log (y_{gi} / L^*_i) = \beta_0 + \beta_1 + ...
$$

## TMM Normalisation

```{r}
dge_filter <- calcNormFactors(dge_filter)
dge_filter$samples
```

::: {.notes}
- The clustering around 1 suggests very similar libraries
:::

## PCA Analysis

- `edgeR` offers `plotMDS()` for quick exploration


```{r plot-mds}
#| output-location: column
#| fig-height: 7
plotMDS(
  dge_filter, 
  col = as.integer(dge_filter$samples$treatment)
)
```

::: {.notes}
- Takes top 500 most variable genes
- Uses base graphics
:::

## PCA Analysis

- logCPM values are very useful for PCA
    + Will now be calculated using the normalisation factors
    
```{r}
pca <- dge_filter %>% 
  cpm(log = TRUE) %>% 
  t() %>% 
  prcomp(center = TRUE, scale. = TRUE)
summary(pca)
prop_var <- summary(pca)$importance["Proportion of Variance",]
```

## PCA Analysis

- PC1 vs PC2 shown below $\implies$ easily modified to other components

:::: {.panel-tabset}

### Simple PCA

```{r plot-pca}
#| fig-show: hide
pca %>% 
  broom::tidy() %>% 
  pivot_wider(names_from = "PC", names_prefix = "PC", values_from = "value") %>% 
  dplyr::rename(id = row) %>% 
  left_join(dge_filter$samples) %>% 
  ggplot(aes(PC1, PC2, colour = treatment)) +
  geom_text(aes(label = id), show.legend = FALSE) +
  scale_colour_brewer(palette = "Set1")
```

::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/plot-pca-1.png)

:::

### Enhanced Axis Labels

```{r plot-pca-labels}
#| fig-show: hide
pca %>% 
  broom::tidy() %>% 
  pivot_wider(names_from = "PC", names_prefix = "PC", values_from = "value") %>% 
  dplyr::rename(id = row) %>% 
  left_join(dge_filter$samples) %>% 
  ggplot(aes(PC1, PC2, colour = treatment)) +
  geom_point() +
  geom_text_repel(aes(label = id), show.legend = FALSE) +
  labs(
    x = glue("PC1 ({percent(prop_var['PC1'])} Variance)"),
    y = glue("PC2 ({percent(prop_var['PC2'])} Variance)"),
    colour = "Treatment"
  ) +
  scale_colour_brewer(palette = "Set1")
```

::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/plot-pca-labels-1.png)

:::

::::

## PCA Analysis

- What do we think the above is telling us?
- Does it look like treatment is contributing to the variance?
- Are there any other potential sources of variability?

::: {.notes}
- Looks to me like samples 2-4 had transfection issues
- Need to discuss with wet lab folks
:::

## The Design Matrix

::: {style="font-size: 92%;"}

- Before proceeding need to define a *design matrix*

```{r}
X <- model.matrix(~treatment, dge_filter$samples)
X
```

:::

## The Design Matrix

- The first column will estimate average expression in control samples
- Remaining columns estimate the difference due to treatments
- (Almost) always modelled on the log2 scale $\implies$ logFC

## Estimating Dispersions

- We can estimate the dispersion parameter across the entire dataset
- `edgeR` models consider technical noise as Poisson with *biological noise* as over-dispersion
- This adds multiple elements to the `DGEList`
    + Essential for `edgeR` models
- Initial estimates are moderated using a global trend during model fitting

```{r}
dge_filter <- estimateDisp(dge_filter, design = X)
```

## Estimating Dispersions

```{r plot-bcv}
#| output-location: column
#| fig-height: 7
# Output uses base graphics no ggplot
plotBCV(dge_filter, pch = 2)
```

## Model Fitting

- The recommended approach for `edgeR` is to use *Quasi-Likelihood* fits [@Lund2012-xo]
    + Allows flexibility in over-dispersion parameters
- First we fit the model $\implies$ then perform testing
- Using our design matrix, we will fit the model for all coefficients in `X`
    + Perform tests within each co-efficient
    + We'll use the 'M' treatment


```{r}
fit <- glmQLFit(dge_filter, design = X)
```

## Model Testing

- Statistical tests use quasi-likelihood F-tests
- Use moderate dispersions (Empirical Bayes)
- By default, the top10 genes are returned

```{r}
fit %>% glmQLFTest(coef = "treatmentM") %>% topTags()
```

## Model Testing

- Can easily collect all genes into a manageable object

```{r}
res_M <- fit %>% 
  glmQLFTest(coef = "treatmentM") %>%
  topTags(n = Inf) %>% 
  as.data.frame() %>% 
  as_tibble()
res_M
```

## Multiple Testing

- Under H~0~: ~1 in 20 random p-values will be < 0.05
- With ~14,000 genes $\implies$ about 700 expected
- These would be Type 1 errors $\implies$ false positives
    + We say something is happening, when it's just noise
    
. . .

- The False Discovery Rate (FDR) controls Type 1 errors at a given rate
    + Using $\alpha = 0.05 \implies$ happy with 5% of results being errors
    + Always just an estimate
    
```{r}
sum(res_M$FDR < 0.05)
```

    
## Inspection of P-values

- Under H~0~ $\implies$ $p \sim \mathcal{U}(0, 1)$
- Under H~A~ no distribution $\implies$ peak near zero

```{r plot-pval}
#| fig-show: hide
res_M %>% 
  ggplot(aes(PValue)) +
  geom_histogram(binwidth = 0.01, fill = "grey70", colour = "black") +
  scale_y_continuous(expand = expansion(c(0, 0.05))) 
```

::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/plot-pval-1.png)

:::

::: {.notes}
Looks as expected
:::

## Volcano Plots

- Plot developed during microarray analysis
- Shows logFC against significance ($p$-values)

```{r plot-volcano}
#| fig-show: hide
res_M %>% 
  ggplot(aes(logFC, -log10(PValue), colour = FDR < 0.05)) +
  geom_point() +
  geom_label_repel(
    aes(label = gene_name),
    data = . %>% 
      arrange(PValue) %>% 
      dplyr::slice(1:10),
    size = 3, show.legend = FALSE
  ) +
  scale_colour_manual(values = c("black", "red")) 
```

::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/plot-volcano-1.png)

:::


## MA Plots

- Two-colour microarray data introduced MA plots
- Signal from two-colour arrays layered treat vs control in a single spot
    + `A` for intensity averages
    + `M` for mean intensity differences
- Still commonly used and the language remains
- Sometimes called MD (mean-difference) plots
    + `edgeR` provides `plotMD()`
- Show average expression on the `x`-axis and logFC on `y`-axis
    + How highly expressed are any DE genes?

## MA Plots

- Often start with an exploration then customise for our data

:::: {.panel-tabset}

### Initial Plot

```{r plot-ma}
#| fig-show: hide
res_M %>% 
  ggplot(aes(logCPM, logFC)) +
  geom_point(aes(colour = FDR < 0.05), alpha = 0.7) +
  scale_colour_manual(values = c("black", "red"))
```

::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/plot-ma-1.png)

:::

### Customised Plot

```{r plot-ma-label}
#| fig-show: hide
res_M %>% 
  arrange(desc(PValue)) %>% # Why do this?
  ggplot(aes(logCPM, logFC, colour = FDR < 0.05)) +
  geom_point(alpha = 0.7) +
  geom_smooth(se = FALSE, colour = 'royalblue3', method = "lm") +
  geom_label_repel(
    aes(label = gene_name),
    data = . %>% 
      dplyr::filter(FDR < 0.05) %>% 
      arrange(desc(abs(logFC))) %>% 
      dplyr::slice(1:10),
    size = 3, show.legend = FALSE
  ) +
  scale_colour_manual(values = c("black", "red")) 
```


::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/plot-ma-label-1.png)

:::

::::

## Filtering of DE Genes

- There is a tendency of the most extreme logFC to be in low expressed genes
- The ratio of any number over a small number will $\rightarrow \infty$
- If there are "too many" DE genes $\implies$ should we filter results?

. . .

- Early approaches were to filter on extreme logFC
- Biased results towards low-expressed genes

## Range-Based Hypothesis Testing

- Traditional H~0~ is $\mu = 0$ against H~A~ $\mu \neq 0$
- An alternative is to use a range-based H~0~ [@McCarthy2009-qf]
- Implemented in `glmTreat()`
- Default range is FC > 20% in either direction

```{r}
res_treatM <- fit %>% 
  glmTreat(coef = "treatmentM", lfc = log2(1.2)) %>% 
  topTags(n = Inf) %>% 
  as.data.frame() %>% 
  as_tibble()
sum(res_treatM$FDR < 0.05)
```

## Range-Based Hypothesis Testing

```{r plot-ma-treat}
#| fig-show: hide
res_treatM %>% 
  arrange(desc(PValue)) %>% # Why do this?
  ggplot(aes(logCPM, logFC, colour = FDR < 0.05)) +
  geom_point(alpha = 0.7) +
  geom_smooth(se = FALSE, colour = 'royalblue3', method = "lm") +
  geom_label_repel(
    aes(label = gene_name),
    data = . %>% 
      dplyr::filter(FDR < 0.05) %>% 
      arrange(desc(abs(logFC))) %>% 
      dplyr::slice(1:10),
    size = 3, show.legend = FALSE
  ) +
  scale_colour_manual(values = c("black", "red")) 
```

::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/plot-ma-treat-1.png)

:::

::: {.notes}
Clearly some high logFC genes had weak statistical support
:::

## Checking Individual Genes

- Checking individual genes for changes in expression can be helpful
- Choosing a small number helps with interpretability

```{r boxplot-topranked}
#| fig-show: hide
cpm(dge_filter, log = TRUE) %>% 
  .[res_treatM$gene_id[1:9],] %>% 
  as_tibble(rownames = "gene_id") %>% 
  pivot_longer(-all_of("gene_id"), names_to = "id", values_to = "logCPM") %>% 
  left_join(dge$genes) %>% 
  left_join(dge$samples) %>%
  mutate(gene_name = fct_inorder(gene_name)) %>% 
  ggplot(aes(treatment, logCPM, fill = treatment)) +
  geom_boxplot() +
  facet_wrap(~gene_name, scales = "free_y") +
  scale_fill_brewer(palette = "Set1")
```

::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/boxplot-topranked-1.png)

:::

## Heatmaps Across Multiple Genes

- Showing larger groups of genes can also be informative
- Enables very basic clustering of genes

. . .

- The package `pheatmap` is a common resource
- Pre-dates the `tidyverse` $\implies$ `matrix` and `data.frame` objects

## Heatmaps Across Multiple Genes

1. Form a matrix from the top genes
2. Subtract the mean expression value
    + This retains variability but shows direction of change
3. Set rownames to be the gene-names

```{r}
mat <- cpm(dge_filter, log = TRUE)[res_treatM$gene_id[1:25],] 
mat <- mat - rowMeans(mat)
rownames(mat) <- setNames(genes$gene_name, genes$gene_id)[rownames(mat)]
```

. . .

- Choosing too many genes can confuse rather than illustrate the results!!!

## Heatmaps Across Multiple Genes

- Groups can be set using column annotations (`annotation_col`)
    + Requires a `data.frame` with rownames 
- Group colours can also be passed as a list

```{r heatmap-topranked}
#| fig-show: hide
pheatmap(
  mat, 
  annotation_col = samples %>%
    dplyr::select(id, treatment) %>% 
    as.data.frame() %>% 
    column_to_rownames("id"),
  annotation_colors = list(
    treatment = setNames(
      RColorBrewer::brewer.pal(4, "Set1"), levels(samples$treatment)
    )
  ),
  cutree_rows = 4
)
```

::: {style="font-size: 75%;"}

[Click to show figure](deg_slides_files/figure-revealjs/heatmap-topranked-1.png)

:::

::: {.notes}
Every column in the annotation df will be added as an annotation
:::

# Using DESeq2 {background-color="#3c3c44" background-image=https://raw.githubusercontent.com/Bioconductor/BiocStickers/devel/DESeq2/DESeq2.png background-size="30%" background-opacity="0.4" background-position='80% 50%'}

## DESeq2

- Another common package for RNASeq analysis is `DESeq2` [@DESeq22014]
- Uses `S4` object more interconnected to other Bioconductor classes
- Different approach to dispersions
- Different statistical testing
- Feels a bit more like a "*black-box*" to me
    + More default settings for a similar workflow $\implies$ fewer manual steps
- Is a very high-quality approach (as is `edgeR`)

## DESeq2

```{r}
library(DESeq2)
library(extraChIPs)
dds <- DESeqDataSetFromMatrix(
  dge_filter$counts, 
  colData = samples,
  rowData = dge_filter$genes %>% 
    makeGRangesFromDataFrame(keep.extra.columns = TRUE),
  design = ~ treatment
)
is(dds)
```

## Summarized Experiment Objects

- `SummarizedExperiment` objects are a core Bioconductor class

```{r}
getSlots("SummarizedExperiment")
```

. . .

- Any number of `assays` can be added
    + Usually matrices with identical dimensions
- `colData` holds the sample-level metadata

## Summarized Experiment Objects

- `RangedSummarizedExperiment` objects are a subclass of `SummarizedExperiment`

```{r}
getSlots("RangedSummarizedExperiment")
```

. . .

- All slots from a `SummarizedExperiment`
- `rowRanges` allow metadata for each row of counts
    + Usually a `GRanges` with optional `mcols`

## DESeqDataSet Objects

- Extends `RangedSummarizedExperiment` objects

```{r}
getSlots("DESeqDataSet")
```

. . . 

- Includes a design matrix & dispersionFunction

## DESeqDataSet Objects

- Multiple data access method exist
    + `colData()`, `rowData()`, `rowRanges()`
    + `assay()`, `counts()`

```{r}
#| results: hide
colData(dds)
rowRanges(dds)
rowData(dds)
assay(dds, "counts") %>% head()
counts(dds) %>% head()
```


## DESeqDataSet Objects

- All functions & methods written for parent classes work with a `DESeqDataSet`
- `tidyomics` specifically developed for `SummarizedExperiment` objects
- Numerous functions & methods for `SummarizedExperiment` objects

. . .

- Let's look at a few from `extraChIPs`
- First add a `logCPM` assay

```{r}
assay(dds, "logCPM") <- cpm(dds, log = TRUE)
assays(dds)
```

::: {.notes}
- I know the methods in `extraChIPs` best given I wrote them. Sorry...
:::

## DESeqDataSet Objects


```{r ec-pca12}
#| output-location: column
plotAssayPCA(
  dds, assay = "logCPM", 
  colour = "treatment", label = "id"
) +
  labs(colour = "Treatment") +
  scale_colour_brewer(palette = "Set1")
```

## DESeqDataSet Objects

```{r ec-pca23}
#| output-location: column
plotAssayPCA(
  dds, assay = "logCPM", 
  colour = "treatment", label = "id",
  pc_x = 2, pc_y = 3 # Change the PCs
) +
  labs(colour = "Treatment") +
  scale_colour_brewer(palette = "Set1")
```

## DESeqDataSet Objects

```{r logcpm-densities}
#| output-location: column
plotAssayDensities(
  dds, "logCPM", colour = "treatment"
  ) +
  labs(colour = "Treatment") +
  scale_colour_brewer(palette = "Set1")
```

## DESeqDataSet Objects

```{r log1p-densities}
#| output-location: column
plotAssayDensities(
  dds, colour = "treatment", trans = "log1p"
  ) +
  labs(colour = "Treatment") +
  scale_colour_brewer(palette = "Set1")
```

## DESeqDataSet Objects

```{r logcpm-rle}
#| output-location: column
plotAssayRle(
  dds, "logCPM", 
  fill = "treatment", by_x = "replicate"
) +
  facet_wrap(
    ~treatment, nrow = 1, scales = "free_x"
  ) +
  labs(fill = "Treatment") +
  scale_fill_brewer(palette = "Set1")
## RLE shows if any sample shows consistently
## higher or lower counts
```

::: {.notes}
- This makes another excellent QC check
- Usually fine, but a good tool to know
:::

## DGE Analysis

- The function `DESeq()` wraps multiple steps
- Normalisation factors $\equiv$ `sizeFactors` added to `colData`
    + Uses the RLE method (very similar to TMM)
- Additional assays will be added along with `rowData` columns
- Testing is performed using the Wald Test

```{r}
dds <- DESeq(dds)
dds
```

## Dispersions

```{r deseq-dispersions}
#| output-location: column
# Dispersions are also moderated by `DESeq2`
plotDispEsts(dds)
```


## DGE Results

```{r}
resultsNames(dds)
res_deseq2_M <- results(dds, name = "treatment_M_vs_control")
res_deseq2_M
```


## DGE Results

- This analysis gave `r comma(sum(res_deseq2_M$padj < 0.05, na.rm = TRUE))` DE genes
- To sort by significance

```{r}
res_deseq2_M %>% 
  as_tibble(rownames = "gene_id") %>% 
  left_join(as_tibble(genes)) %>% 
  arrange(pvalue) %>% 
  dplyr::select(range, starts_with("gene"), everything())
```

::: {.notes}
This takes advantage of `as_tibble()` twice. Once to convert a `DataFrame`, with
the second to convert a `GRanges`
:::

## Visualising Results

```{r deseq-ma}
#| output-location: column
plotMA(res_deseq2_M)
```


## Filtering Results

::: {style="font-size: 90%;"}

- The approach taken by `DESeq2` is different from `edgeR`'s range-based H~0~
- Shrinks the estimates of logFC [@Zhu2019-kg]
- Returns `s`-values (false sign or small)

```{r}
res_lfcshrink_M <- lfcShrink(
  dds, "treatment_M_vs_control", lfcThreshold = log2(1.2)
)
res_lfcshrink_M
```

:::

## Filtering Results

- This has reduced the original `r comma(sum(res_deseq2_M$padj < 0.05, na.rm = TRUE))` DE genes to `r comma(sum(res_lfcshrink_M$svalue < 0.05))`

```{r}
res_lfcshrink_M %>% 
  as_tibble(rownames = "gene_id") %>% 
  left_join(as_tibble(genes)) %>% 
  arrange(svalue) %>% 
  dplyr::filter(svalue < 0.05) %>% 
  dplyr::select(range, starts_with("gene"), everything())
```

## Comparison of Approaches

- Using the most conservative analyses
- Genes along zero for `DESeq2` were a result of shrinkage

```{r plot-compare}
#| echo: false
#| fig-align: left
dplyr::select(res_treatM, gene_id, logFC, FDR) %>% 
  left_join(
    res_lfcshrink_M %>% 
      as_tibble(rownames = "gene_id") %>% 
      dplyr::select(gene_id, log2FoldChange, svalue),
    by = "gene_id", suffix = c("edgeR", "DESeq2")
  ) %>% 
  left_join(as_tibble(genes), by = "gene_id") %>% 
  mutate(
    Status = case_when(
      FDR < 0.05 & svalue < 0.05 ~ "Both",
      FDR < 0.05 ~ "edgeR Only",
      svalue < 0.05 ~ "DESeq2 Only",
      TRUE ~ "Neither"
    )
  ) %>% 
  ggplot(aes(logFC, log2FoldChange, colour = Status)) +
  geom_point() +
  geom_abline(slope = 1) +
  geom_text_repel(
    aes(label = gene_name),
    data = . %>% dplyr::filter(abs(logFC) > 4.5, Status != "Neither"),
    show.legend = FALSE
  ) +
  labs(x = "logFC (edgeR)", y = "shrunken logFC (DESeq2)") +
  scale_colour_manual(
    values = c("forestgreen", "skyblue3", "orange3", "grey")
  )
```

## Export Results

- Save the `DGEList` using the following

```{r}
write_rds(dge_filter, here::here("data/dge_filter.rds"))
```


- Save the `edgeR` results using the following

```{r}
write_rds(res_treatM, here::here("data/res_treatM.rds"))
```

## Conclusion

- `DESeq2` data structures integrate nicely with other Bioconductor packages
- `edgeR` can also handle `SummarizedExperiment` objects (mostly)
- No right or wrong method or data classes to use
    + Results were still broadly consistent
- `DESeq2` also has many options for parameter/model choice not covered here

. . .

- `SummarizedExperiment` objects share much with `SingleCellExperiment` objects
- Have helped with multiple analyses & seem preferable to `Seurat` (IMHO)
    + `Seurat` is everywhere but I spend a lot of time debugging for people

## References

    
